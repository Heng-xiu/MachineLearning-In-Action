{
  
    
        "post0": {
            "title": "第一次上傳 Jupyter 使用 NLP 作業做範例",
            "content": "About . 本篇文章主要展現如何快速搭建資料科學相關部落格，文章內容格式可以使用 .ipynb 或是 .word 來做撰寫。 可以先在 Local Machine 使用 Make server 開啟 Local Blog 之後，再使用 make convert 來轉換成 .md 接著就可以上傳成 Branch, 發動 pull request, 來自動 merge 到 Master . import pandas as pd import numpy as np . Read Dataset from Sentiment Labelled Sentences Data Set . filepath_dict = {&#39;yelp&#39;: &#39;./sentiment labelled sentences/yelp_labelled.txt&#39;, &#39;amazon&#39;: &#39;./sentiment labelled sentences/amazon_cells_labelled.txt&#39;, &#39;imdb&#39;: &#39;./sentiment labelled sentences/imdb_labelled.txt&#39;} df_list = [] for source, filepath in filepath_dict.items(): df = pd.read_csv(filepath, names=[&#39;sentence&#39;, &#39;label&#39;], sep=&#39; t&#39;) df[&#39;source&#39;] = source # Add another column filled with the source name df_list.append(df) df = pd.concat(df_list) print(df.iloc[0]) . sentence Wow... Loved this place. label 1 source yelp Name: 0, dtype: object . CountVectorizer . from sklearn.feature_extraction.text import CountVectorizer sentences = [&#39;John likes ice cream&#39;, &#39;John hates chocolate.&#39;] vectorizer = CountVectorizer(min_df=0, lowercase=False) vectorizer.fit(sentences) vectorizer.vocabulary_ . {&#39;John&#39;: 0, &#39;likes&#39;: 5, &#39;ice&#39;: 4, &#39;cream&#39;: 2, &#39;hates&#39;: 3, &#39;chocolate&#39;: 1} . vectorizer.transform(sentences).toarray() . array([[1, 0, 1, 0, 1, 1], [1, 1, 0, 1, 0, 0]]) . Define a Baseline Model . from sklearn.model_selection import train_test_split from sklearn.linear_model import LogisticRegression df_yelp = df[df[&#39;source&#39;] == &#39;yelp&#39;] sentences = df_yelp[&#39;sentence&#39;].values y = df_yelp[&#39;label&#39;].values sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.25, random_state=1000) ## vectorizer = CountVectorizer() ## vectorizer.fit(sentences_train) ## X_train = vectorizer.transform(sentences_train) X_test = vectorizer.transform(sentences_test) ## Classifier classifier = LogisticRegression() classifier.fit(X_train, y_train) score = classifier.score(X_test, y_test) print(&quot;Accuracy:&quot;, score) . Accuracy: 0.796 . Apply DNN . from keras.models import Sequential from keras import layers input_dim = X_train.shape[1] # Number of features model = Sequential() model.add(layers.Dense(10, input_dim=input_dim, activation=&#39;relu&#39;)) model.add(layers.Dense(1, activation=&#39;sigmoid&#39;)) model.compile(loss=&#39;binary_crossentropy&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;]) model.summary() . Using TensorFlow backend. WARNING: Logging before flag parsing goes to stderr. W0812 15:03:07.597831 4590767552 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead. W0812 15:03:07.612365 4590767552 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead. W0812 15:03:07.615277 4590767552 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead. W0812 15:03:07.644843 4590767552 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead. W0812 15:03:07.667706 4590767552 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead. W0812 15:03:07.673678 4590767552 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.&lt;locals&gt;.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version. Instructions for updating: Use tf.where in 2.0, which has the same broadcast rule as np.where . _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_1 (Dense) (None, 10) 17150 _________________________________________________________________ dense_2 (Dense) (None, 1) 11 ================================================================= Total params: 17,161 Trainable params: 17,161 Non-trainable params: 0 _________________________________________________________________ . history = model.fit(X_train, y_train,epochs=100,verbose=False,validation_data=(X_test, y_test),batch_size=10) . W0812 15:03:07.856102 4590767552 deprecation_wrapper.py:119] From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead. . loss, accuracy = model.evaluate(X_train, y_train, verbose=False) print(&quot;Training Accuracy: {:.4f}&quot;.format(accuracy)) loss, accuracy = model.evaluate(X_test, y_test, verbose=False) print(&quot;Testing Accuracy: {:.4f}&quot;.format(accuracy)) . Training Accuracy: 1.0000 Testing Accuracy: 0.7920 . Visualize your report . import matplotlib.pyplot as plt plt.style.use(&#39;ggplot&#39;) def plot_history(history): acc = history.history[&#39;acc&#39;] val_acc = history.history[&#39;val_acc&#39;] loss = history.history[&#39;loss&#39;] val_loss = history.history[&#39;val_loss&#39;] x = range(1, len(acc) + 1) plt.figure(figsize=(12, 5)) plt.subplot(1, 2, 1) plt.plot(x, acc, &#39;b&#39;, label=&#39;Training acc&#39;) plt.plot(x, val_acc, &#39;r&#39;, label=&#39;Validation acc&#39;) plt.title(&#39;Training and validation accuracy&#39;) plt.legend() plt.subplot(1, 2, 2) plt.plot(x, loss, &#39;b&#39;, label=&#39;Training loss&#39;) plt.plot(x, val_loss, &#39;r&#39;, label=&#39;Validation loss&#39;) plt.title(&#39;Training and validation loss&#39;) plt.legend() plot_history(history) . Word Embedding by yourself . from keras.preprocessing.text import Tokenizer tokenizer = Tokenizer(num_words=5000) tokenizer.fit_on_texts(sentences_train) X_train = tokenizer.texts_to_sequences(sentences_train) X_test = tokenizer.texts_to_sequences(sentences_test) vocab_size = len(tokenizer.word_index) + 1 # Adding 1 because of reserved 0 index print(sentences_train[2]) print(X_train[2]) . Of all the dishes, the salmon was the best, but all were great. [11, 43, 1, 171, 1, 283, 3, 1, 47, 26, 43, 24, 22] . for word in [&#39;the&#39;, &#39;all&#39;, &#39;happy&#39;, &#39;sad&#39;]: print(&#39;{}: {}&#39;.format(word, tokenizer.word_index[word])) . the: 1 all: 43 happy: 320 sad: 450 . Different Sequence_length among sentences . from keras.preprocessing.sequence import pad_sequences maxlen = 100 X_train = pad_sequences(X_train, padding=&#39;post&#39;, maxlen=maxlen) X_test = pad_sequences(X_test, padding=&#39;post&#39;, maxlen=maxlen) print(X_train[0, :]) . [ 1 10 3 282 739 25 8 208 30 64 459 230 13 1 124 5 231 8 58 5 67 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] . ### Embedding Model . from keras.models import Sequential from keras import layers embedding_dim = 50 model = Sequential() model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen)) model.add(layers.Flatten()) model.add(layers.Dense(10, activation=&#39;relu&#39;)) model.add(layers.Dense(1, activation=&#39;sigmoid&#39;)) model.compile(optimizer=&#39;adam&#39;, loss=&#39;binary_crossentropy&#39;, metrics=[&#39;accuracy&#39;]) model.summary() . _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_1 (Embedding) (None, 100, 50) 87350 _________________________________________________________________ flatten_1 (Flatten) (None, 5000) 0 _________________________________________________________________ dense_3 (Dense) (None, 10) 50010 _________________________________________________________________ dense_4 (Dense) (None, 1) 11 ================================================================= Total params: 137,371 Trainable params: 137,371 Non-trainable params: 0 _________________________________________________________________ . history = model.fit(X_train, y_train, epochs=20, verbose=False, validation_data=(X_test, y_test), batch_size=10) loss, accuracy = model.evaluate(X_train, y_train, verbose=False) print(&quot;Training Accuracy: {:.4f}&quot;.format(accuracy)) loss, accuracy = model.evaluate(X_test, y_test, verbose=False) print(&quot;Testing Accuracy: {:.4f}&quot;.format(accuracy)) plot_history(history) . Training Accuracy: 1.0000 Testing Accuracy: 0.7480 .",
            "url": "https://heng-xiu.github.io/MachineLearning-In-Action/jupyter/nlp/machine%20learning/2020/08/12/NLP.html",
            "relUrl": "/jupyter/nlp/machine%20learning/2020/08/12/NLP.html",
            "date": " • Aug 12, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://heng-xiu.github.io/MachineLearning-In-Action/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://heng-xiu.github.io/MachineLearning-In-Action/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "關於我",
          "content": "本資料科學部落格主要是整體課程中，關於機器學習、深度學習的各種文章，並且帶有 DEMO CODE，方便後進人員，方便閱讀。 . 本資料科學部落格是採用 fastpages 1 進行搭建，更多資訊可以點開連結，進行查閱。 . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://heng-xiu.github.io/MachineLearning-In-Action/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://heng-xiu.github.io/MachineLearning-In-Action/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}